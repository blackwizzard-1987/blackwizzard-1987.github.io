---
layout:     post
title:      TiDB异地两中心延迟测试
subtitle:  	
date:       2021-05-13
author:     RC
header-img: 
catalog: true
tags:
    - TiDB
    - 异地双活
    - 高可用
---

## 0. 测试背景

由于目前业务系统和报表系统的交叉性，同一机房的一整套tidb群集需要进行单机房到异地双机房实现扩充和双活的要求，结合tidb官方给出的两中心单集群偶数副本方案：

![1](https://i.postimg.cc/yYbQzckZ/image.png)

作为候选方案之一，因此有了下文的测试

## 1. 测试目的

- 观察写入2000W数据时raft IO，raft process，raft propose， pd request，pd gRPC延迟，heartbeat lagency等的延迟状况截图

- 观察扩容到6节点6副本后上述的延迟情况

- 测试pd-ctl直接扩容3节点后更改集群label和副本数是否有问题

- 测试任一机房的3节点宕机后，直接修改副本数能否拉起服务

## 2. 准备工作

### 2.1 拓扑结构

| 模拟机房 | 服务器IP | 组件 |
| --- | --- | --- |
| 上海 | xx.31.xx.30/31/32 | pd/tikv/tidb |
| 广州 | xx.29.xx.30/31/32 | pd/tikv/tidb |
| 上海 | xx.31.xx.29 | tiup/Prometheus/grafana |

所有机器均通过腾讯云根据地域选择部署，保证异地性质(目前ping在28ms)

### 2.2 环境准备

```html
 建立中控机xx.31.xx.29到上海机房3个节点的root/tidb用户的SSH信任关系 

中控机安装tiup：
$ curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh
$ source /root/.bash\_profile
$ which tiup 

配置tidb安装包镜像
$ tar xzvf tidb-community-server-v4.0.9-linux-amd64.tar.gz && \
sh tidb-community-server-v4.0.9-linux-amd64/local_install.sh && \
source /home/tidb/.bash_profile

编辑tidb拓扑结构配置文件
# # Global variables are applied to all deployments and used as the default value of
# # the deployments if a specific deployment value is missing.
global:
  user: "tidb"
  ssh_port: 33864
  deploy_dir: "/tidb-deploy"
  data_dir: "/tidb-data"

server_configs:
  tidb:
    log.file.max-days: 10
    mem-quota-query: 21474836480
    oom-action: cancel
    performance.txn-total-size-limit: 10737418240
  tikv:
    raftstore.hibernate-regions: true
  pd:
    replication.enable-placement-rules: true
    schedule.enable-cross-table-merge: true
    schedule.max-merge-region-size: 40
    schedule.max-merge-region-keys: 400000
    schedule.patrol-region-interval: 50ms

pd_servers:
  - host: xx.31.xx.30
  - host: xx.31.xx.31
  - host: xx.31.xx.32
tidb_servers:
  - host: xx.31.xx.30
  - host: xx.31.xx.31
  - host: xx.31.xx.32
tikv_servers:
  - host: xx.31.xx.30
  - host: xx.31.xx.31
  - host: xx.31.xx.32
monitoring_servers:
  - host: xx.31.xx.29
grafana_servers:
  - host: xx.31.xx.29
alertmanager_servers:
  - host: xx.31.xx.29

部署tidb
$ tiup cluster deploy tidb v4.0.9 topology.yaml --user root -p 

安装pd-ctl工具
$ cd /install/tidb-community-server-v4.0.9-linux-amd64
$ tar -xvzf ctl-v4.0.9-linux-amd64.tar.gz
$ ln -s /install/tidb-community-server-v4.0.9-linux-amd64/pd-ctl /usr/bin/pd-ctl
$ ln -s /root/.tiup/bin/tiup /usr/bin/tiup
$ pd-ctl -i -u http://xx.31.xx.30:2379
$ tiup cluster display tidb |
```

## 3. 两地2中心延迟测试

延迟测试均通过lighting还原一张2300W的表，并观察不同情况下的写延迟情况 

### 3.1 观察单机房下的写延迟

图片较多，不再赘述

### 3.2 扩容到6KV并修改KV标签和region副本数

```html
打通中控机到广州3节点的root和tidb用户的ssh通信

设置kv扩容文件 
tikv_servers:
- host: xx.29.xx.30
  ssh_port: 33864
  port: 20160
  status_port: 20180
  deploy_dir: /tidb-deploy/tikv-20160
  data_dir: /tidb-data/tikv-20160
  arch: amd64
  os: linux

- host: xx.29.xx.31
  ssh_port: 33864
  port: 20160
  status_port: 20180
  deploy_dir: /tidb-deploy/tikv-20160
  data_dir: /tidb-data/tikv-20160
  arch: amd64
  os: linux

- host: xx.29.xx.32
  ssh_port: 33864
  port: 20160
  status_port: 20180
  deploy_dir: /tidb-deploy/tikv-20160
  data_dir: /tidb-data/tikv-20160
  arch: amd64
  os: linux

$ tiup cluster scale-out tidb tikv_scale_out.yaml
等待群集分散region和leader
观察新加入的tikv节点日志，当不再持续出现add peer successfully，说明群集已经达到平衡
同时观察pd-ctl中各个store的region变化
可以看到3副本6kv的情况下几乎没有规律可循，pd只是打散了region和leader，而region的分散导致2个节点丢失=丢数据的风险与3副本丢2相当
可知其高可用性没有得到提升

pd-ctl中设置标签项
$ pd-ctl -i -u http://xx.31.xx.32:2379
$ config set location-labels dc,rack,host

通过tiup修改tikv的server config
$ tiup cluster edit-config tidb
  config:
    server.labels:
      dc: d1
      host: h1
      rack: r1


通过pd-ctl修改kv 1214的label
$ store label 1214 dc d2 rack r6 host h6

修改副本数为6
$ config set max-replicas 6

因4.0.2版本后默认开启placement-rules，该设置会屏蔽其他地方的配置
$ config placement-rules show
由json文件控制:
[
    {
        "group_id": "pd",
        "id": "default",
		"start_key": "",
		"end_key": "",
        "role": "voter",
        "count": 6,
        "location_labels": ["dc", "rack", "host"]
    }
]
$ config placement save --in=placement_rule.json
$ config placement-rules show
之后，观察到kv开始补充副本，最后达到6个54个region的1:1效果，符合预期

删除之前的placement配置
将json文件的count一行删除(或改为0)，保存即可
$ config placement save --in=placement_rule.json
deleted rule pd/default

通过placement进行leader的分配管理
[
    {
        "group_id": "pd",
        "id": "d1",
        "start_key": "",
        "end_key": "",
        "role": "voter",
        "count": 3,
        "label_constraints": [
            {"key": "dc", "op": "in", "values": ["d1"]}
        ],
        "location_labels": ["dc", "rack", "host"]
    },
    {
        "group_id": "pd",
        "id": "d2",
        "start_key": "",
        "end_key": "",
        "role": "follower",
        "count": 3,
        "label_constraints": [
            {"key": "dc", "op": "in", "values": ["d2"]}
        ],
        "location_labels": ["dc", "rack", "host"]
    }
]
需要检查各个kv的标签是否完全正确
$ store
配置完成后观察到上海机房的kv被选举为leader，广州机房的kv不再持有leader
此外，该配置还可以精确到region，并且可以配合isolation-level完成单个机房不满足N个副本条件时的物理隔离
```

### 3.3 观察双机房下的写延迟

```html
控制变量：leader全在广州

测试读写请求在上海
(推测会多走一次专线来回，因为响应的leader在广州)
差异比较大的指标：
pd request duration
2ms-> 50ms
raft IO commit log duration
2-4ms -> 16-32ms
指标1从扩为6节点3副本之后就直接升高了
指标2扩容后几乎不变，改为6副本后升高

读写请求在广州的延迟
raft IO commit log duration
16-32ms -> 32ms-64ms
pd request duration
50ms->60ms
apply log duration 
8-16ms -> 128-256ms
各项指标均升高

控制变量：leader分散

apply log duration 60ms -> 200ms

raft机制：leader负责读写请求，其余两个副本只复制
```

**可以认为比目前的情况+200ms延迟**

## 4. 数据中心灾难发生后拉起服务测试


任一机房的3节点宕机后，直接修改副本数能否拉起：

否

```html
目前看来pd多数节点宕机影响较大，
使用pd-recover恢复一个pd节点后，通过该节点下线宕机机房的所有节点的组件，
之后缩容->扩容剩余2个pd节点的pd，
然后在关闭的tikv节点上执行
$ tikv-ctl --db /tidb-data/tikv-20160/db/ unsafe-recover remove-fail-stores -s 1213,1214,1215 --all-regions
清除之前缩容掉的模拟宕机的机房的store的信息
之后重启群集，服务可以拉起，恢复为3kv3副本状态
```

详情：[https://asktug.com/t/topic/70074/22](https://asktug.com/t/topic/70074/22)

恢复到机房宕机之前的状态步骤：

```html
等待宕机机房机器启动后，pd会依照3副本的策略调度region和leader到进程已经启动的宕机机房节点上的kv
pd-ctl中store显示了6个kv，但tiup中没有
此时对宕机机房的3个节点进行tikv扩容
显示Tombstone状态，pd-ctl store恢复为3个kv
将3台宕机节点的kv再次缩容
重复pd,tidb的扩容->缩容的步骤，彻底将宕机节点的tidb组件删除
之后，按照先扩容3kv(新的store 10402-404)，然后设置placement rule的步骤恢复到6kv6副本(leader分散)
最后按需要扩容tidb和pd
重启集群即可
```

## 5. 结论

| 方案 | 优点 | 缺点 |
| --- | --- | --- |
| 两地双中心6kv6副本(单中心3kv3副本) | kv标签，Leader可控; 可以双写; 两中心数据对称，可以在人工干预的情况下实现高可用 | 因pd必须满足大多数存活的条件，2个中心（1+2/3+3）的高可用性难以保证; 读写延迟增加200ms+ |

综上，实现无需人工干预的异地多活还是需要至少3个DC，使用6副本或者5副本对应KV数，采用2+2+1/2的机房副本分布，才能保证单一DC灾难后集群仍可继续对外提供服务

## 6. 参考

[https://book.tidb.io/session4/chapter4/two-dc-raft.html](https://book.tidb.io/session4/chapter4/two-dc-raft.html)

[https://docs.pingcap.com/zh/tidb/v4.0/configure-placement-rules#placement-rules-%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3](https://docs.pingcap.com/zh/tidb/v4.0/configure-placement-rules#placement-rules-%E4%BD%BF%E7%94%A8%E6%96%87%E6%A1%A3)

[https://docs.pingcap.com/zh/tidb/v4.0/pd-control#%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85](https://docs.pingcap.com/zh/tidb/v4.0/pd-control#%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85)