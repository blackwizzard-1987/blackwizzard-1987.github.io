---
layout:     post
title:      知识图谱绘制和ETL过程整理(下)
subtitle:
date:       2024-06-03
author:     RC
header-img:
catalog: true
tags:
    - 知识图谱
    - 图数据库
    - NebulaGraph
    - 大数据
    - ETL
---

### 关于NebulaGraph

出于查询性能、存储和可扩展性考虑，我们最后选择了NebulaGraph替代Neo4j作为产品正式上线的底层图数据库服务。

NebulaGraph是国产的开源图数据库，基于Apache 2.0 条款下开发，性能非常卓越，并且支持openCypher查询语言，具体可以看下他们的[DB手册](https://docs.nebula-graph.com.cn/3.8.0/1.introduction/1.what-is-nebula-graph/)。

但是在使用之初，还是有一定的学习成本，并且我们需要**从Neo4j把数据迁移到NebulaGraph并且适配新的查询**，过程中还是遇到了一些问题。这篇文章通过实际本体建模和构建图谱的ETL过程中的经历和克服的困难进行了简单的总结，并展示了阶段性成果。

> NebulaGraph本身支持**分布式集群部署**，通过console的add host添加副本机器，并且可以通过Docker Compose安装，非常的方便，当然，我们也可以在虚拟机上**单机安装**进行测试

> NebulaGraph拥有**图形化界面的NebulaGraph Studio**，可以完成/查看本体建模的shcema，创建space、tag、edge、index等，完成少量数据的import工作，**易用性很强**

> 目前NebulaGraph可以免费使用约20天的企业版，只需要在阿里云上面提交申请，自动部署生成实例，参考[从云开始（免费试用）](https://docs.nebula-graph.com.cn/3.8.0/2.quick-start/2.start-free-trial-on-cloud/)，听说有炫酷的3D渲染图形效果

#### 图空间(space)

Neo4j社区版一大诟病就是一个Neo4j数据库实例只能拥有一个类似于关系型数据库的database。而社区版的NebulaGraph则可以直接**通过图空间（space）将不同领域的数据进行隔离**，相当于可以同时存在互不影响的多个database供用户使用，每个图空间都可以指定不同的存储副本数、权限、分片等。这也是基于分布式存储的优势。

图空间还提供了整个space下面的**各个基本模型的定义**，以及整个图谱的**点、边统计，按tag计数**，还有类似于**本体构建**的view schema和对应的schema drafting：

![1](https://i.postimg.cc/SsVvkkbk/1.png)

![2](https://i.postimg.cc/Jh5T5MnZ/2.png)

#### ETL的不同

Neo4j中为了增量导入数据，我们的ETL都是通过load csv形式实现的，这和NebulaGraph有一定的区别。

在NebulaGraph中，常用的数据导入方式分为五种：

- **图形化操作**：通过NebulaGraph Studio的import功能，管理数据源和创建导入任务实现ETL，本质是csv文件的导入，需要通过csv的列值映射（mapping）到vid、prop、rank上，对于**小型数据集**来说比较效率。创建的任务也可以重复执行，并且可以自定义名字，修改内容，上传的csv文件可以覆盖进行数据、结构等的更新

- **nGQL语句**：通过nGQL语法的Insert语句，在NebulaGraph Console的**白屏命令**中直接执行，虽然更加直接，但需要实现对Insert语句按照语法进行值的拼接

- **NebulaGraph Importer**：是一款NebulaGraph的**CSV文件单机导入**工具，可以读取并批量导入多种数据源的 CSV文件数据，还支持批量更新和删除操作。其本质也是csv文件的导入，但是每个任务都需要手动配置importer的xml配置文件

- **NebulaGraph Exchange**：是一款 Apache Spark应用，用于在分布式环境中将集群中的数据批量迁移到 NebulaGraph 中，能支持多种不同格式的批式数据和流式数据的迁移。一般是Neo4j、Hive、MySQL等多种源分布式导入，需要有Spark集群，适用于**大量数据**，十亿条数据以上的场景

- **编写程序**：通过**C++/GO/Java/Python SDK编写程序**导入数据，需要有一定编程和调优能力，简单版的也可以拼接数据为nGQL语句然后execute

上面的五种方式由于目前第一版产品的数据量限制还没有使用过NebulaGraph Exchange。

其中和Neo4j最相似又有巨大不同的就是涉及csv导入的方式。

在Neo4j中，csv的导入可以和图数据库中的查询操作一起进行，在固定csv的某一行后，我们就可以用它的值去match图数据库中的点了，这在某种程度上可以**极大的减少csv文件的数量**，你甚至可以在同一个csv中同时创建tag和导入点的tag的属性的值，并同时导入多个类型的实体和它们的关系

但在NebulaGraph Exchange的csv导入中，**列的mapping限制了对csv行的操作**，使得整个导入必须严格按照vid列、tag的属性值列、edge的source vid列、destination vid列、edge的属性值列、edge的rank列**建立和csv文件的列的映射关系进行导入**，这样会带来两个问题：

- csv文件的数据**无法在导入时和图数据库的数据进行关联查询**、筛选等

- **很难把N个实体和它们的关系融合进一个csv中**（比如人的属性和人的家庭关系、社会关系等）

对于拥有很多不同edge的图谱来说，为了提高效率，就不得不去维护一个专门的tag csv和它们的关系csv，其中**包含了源目标的vid和边的属性值、rank值**，同样也会导致csv文件变得很多，难以维护。

> 前期demo构建后，项目后期基本都通过导入关系型数据库表的方式，然后**程序化处理原来的csv文件的数据**了，考虑到今后的扩展和数据量成倍增加，这是不得不做的一件事

当然，通过NebulaGraph Studio的import功能对csv进行导入确实是比较易用的，图形化的操作加上任务的一定编排功能使得整个ETL变得机械化和模板化，但同时也提高了**csv的维护成本**。

#### 标签(Tag)

#### 点(vertex)

##### Vid

#### 边(Edge)

#### Rank

#### 索引(Index)

#### nGQL和Cypher

#### 其他优缺点

### 总结和展望

### 参考

