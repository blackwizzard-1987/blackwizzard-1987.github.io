---
layout:     post
title:      Redis巡检系统方案
subtitle:
date:       2022-05-03
author:     RC
header-img:
catalog: true
tags:
    - Redis
    - 巡检
    - 容器化
---

### 背景

公司Redis集群开源Redis Cluster进行二次开发，提供了高吞吐、低延迟的内存数据库服务。支持String、Zset、Hash、Set、List等数据

结构。目前线上集群总QPS峰值超过2亿，总内存1000TB，18Wcore。单集群最大QPS 1500W，400分片/4TB。简单的get/set命令 P999

可以控制在5ms以内。线上按照各个业务线、活动、特殊使用、双活/多活等共计有1000+集群。

由于线上集群过多，人工排查一些问题相当困难，迫切需要一个巡检系统来进行集群、中间件、底层虚拟机的各项数据的量化和整合，这不仅

是为了运维人员的更方便高效的运维，也能及时发现和解决隐患问题，提高整体稳定性。

在运维Redis的过程中，遇到的痛点有：

- 线上集群元数据不准确，导致扩容失败

- 故障机器生命周期不明确，导致该机器一直得不到维修

- 有些集群设置特殊参数，重启导致参数失败

- Redis实例机器分布不清楚，可能存在大于1/4实例位于同一台node上，有数据丢失隐患

- 碎片率不合理，占用内存空间大得不到优化

- 集群QPS倾斜，存在热key

- 日常运维时与业务人员沟通需要人肉操作（抓包、脚本扫描...）去获得相关数据

- 大集群一直空闲，利用率低下，常年失修，毫无知觉

- 缺乏系统科学的数据去治理不断扩大的集群

- 等等

### 目标

开发巡检洗头头痛，能够帮助运维人员及时发现隐患，降低故障风险、提高服务稳定性，如

- 及时发现系统中存在的隐患

- 及时发现配置不标准的参数

- 及时发现不规范、不标准的行为

此外，巡检系统本身也有一定要求

- 巡检系统本身的稳定性和可扩展性

- 每个巡检方案找到的隐患都有对应的解决方案

### 方案

#### 架构

##### 应用层

1. 集成到运维平台，展示隐患明细，巡检结果展示

2. 隐患治理催办，用来督促DBA处理隐患。催办内容中会带有隐患具体内容、出现时长、处理方案等

3. 运营报表->隐患趋势，隐患治理近战

4. 风险点预测，巡检周报

##### 存储层

1. 将发现的隐患都保存造数据库中，包含各种信息方便展示和统计

2. 将巡检程序代码放在gitlab中方便管理和维护

##### 执行层

1. 执行环境： 将巡检程序部署在多个k8s cronjob中分时段起pod进行调度

2. 任务调度： k8s cronjob

3. 巡检目标：所有线上Redis集群-> 分区/分业务线 -> 重点目标

#### 巡检项目

可以分为3大类：

- 集群：集群拓扑、核心参数

- 机器：服务器硬件层面

- 高可用/中间件/备份/key：corvus等核心功能组件

1.K8s集群

```html
巡检项目：k8s组可用资源数量
巡检指标：每个k8s资源置放组保证至少有10个node和10个pod可以创建，redis分片资源单位：2c 16g，corvus资源单位：1.1c 2.2g
巡检频率：每天
备注：保证扩容、新建集群、高可用机制
```

```html
巡检项目：故障机器生命周期
巡检指标：所有状态为SchedulingDisabled的node，存活一周以上，内存版本非最新（tencent001）
巡检频率：每天
备注：老集群比较多，流程化，需要确认
```

```html
巡检项目：部分redis集群或者corvus没有选择nodeselector分组
巡检指标：高危，会导致pod分配混乱，不满足亲和性要求
巡检频率：每天
备注：数量较少，巡检出来后通过运维平台前端限制
```

```html
巡检项目：cvm整体CPU使用率高
巡检指标：单个cvm的CPU使用率过去一天超过1.2小时的时间超过60%
巡检频率：每天
备注：子机负载高会影响母机，要保证SS0等重要集群的cvm负载有冗余
```

```html
巡检项目：cvm没有pod running
巡检指标：cvm除了系统自带的pod外，没有分配到其他的pod
巡检频率：每周
备注：方便整理资源组和知晓cvm闲置情况
```

```html
巡检项目：cvm docker config file配置内容错误
巡检指标：/etc/docker/daemon.json是否为最老的SRE修改版本
巡检频率：每周
备注：该文件配置错误会导致docker镜像拉取失败
```

2.Redis集群

```html
巡检项目：配置参数
巡检指标：rdb开启策略，记录开启rdb的分片；慢查询参数；内存淘汰策略；其他重要参数（内存）
巡检频率：每天
备注：save参数/aof参数/max memory参数
```

```html
巡检项目：集群分片离散性
巡检指标：同一分片的主从pod是否在同一node上；同一集群是否存在1/4以上pod在同一个node上；如果集群小于一定规模，不允许任何2个pod在同一个node上
巡检频率：每天
备注：防止大多数master不可用，数据丢失，集群gossip无法工作
```

```html
巡检项目：集群指标使用率过高
巡检指标：cpu大于100%，内存大于90%，出/入带宽，连接数等每天过去0-24时回溯、总结性的统计
巡检频率：每天
备注：内存/CPU/QPS/出入带宽展示大盘，相应阈值可以动态调整
```

```html
巡检项目：使用exists命令
巡检指标：通过监控数据获取，包括查询频率
巡检频率：每天
备注：4.0.8之前的版本exists有bug，exists存在的key get不到（惰性删除导致）
```

```html
巡检项目：碎片率
巡检指标：mem_fragmentation_ratio  = used_memory_rss / used_memory 大于1.5
巡检频率：每天
备注：找到后可以设置dfrage参数缓慢整理
```

```html
巡检项目：内存增长较快
巡检指标：Redis集群过去一天的整体内存使用率相比前天有2小时以上增长超过20%
巡检频率：每天
备注：找出潜在的内存使用率增长较快的Redis集群，及时扩容/与业务沟通
```

3.中间件corvus和同步组件rmt

```html
巡检项目：corvus镜像版本
巡检指标：检查corvus镜像版本是否过旧，防止内存泄漏问题
巡检频率：每天
备注：找出corvus不规范的旧版本，通过rc/deployment进行更新
```

```html
巡检项目：corvus存活
巡检指标：部分集群因各种原因已经没有corvus，没有流量，但是状态还是在线
巡检频率：每天
备注：找出不再使用的闲置集群（QPS一个月内每天最大值都小于阈值）进行清理
```

```html
巡检项目：RMT配置参数
巡检指标：rmt配置文件中的source ip和target ip的pod是否因为重启等原因发生了变化
巡检频率：每半小时
备注：及时发现pod ip变更问题，进行修正，保证同步的时效性
```

#### 健康度计算

通过巡检项目的扫描结果刷新对应Redis集群、cvm的健康度，并根据健康度在运维平台展示扣分细节，方便查看

### 前端设计

大致参考腾讯云DB Brain界面，主要分为两块：

- 根据隐患维度来展示

从该界面能直观地看到当前存在的隐患数量，点击可以看到隐患详情界面，即通过隐患查看集群

- 根据集群健康度展示

从该界面能直观地看到当前高危集群的健康状况，点击可以看到该集群的隐患详情页面，即通过集群查看隐患

> 其实都是一套数据，只是展示的角度不同

### 后端设计

1.脚本的稳定性和效率

- 控制脚本的并发度，对Redis/k8s api的侵入性

- 脚本run的时间非高峰期（凌晨1-5点）

- 脚本代码review

2.脚本调度

- 通过k8s自带的k8s cronjob进行调度，方便控制和保证稳定性

3.脚本存储和更新

- 通过github管理脚本

- 非复杂逻辑的巡检项目尽量模块化、模板化，在新需求时能够快速生成巡检项目代码

### 巡检项多线程代码示例

```javascript
使用go routine，需要控制线程并发度
func Check***Redis***Multi() {
	//k8s集群转换参数和白名单
	for _, k8sZone := range scanZone  {
    //获取对应k8s的redis cluster struct列表
		cluster_list, _ := get***Func(zone)
		lenc := len(cluster_list)
		timeout := 60
		taskComplete := 0
		//总channel slice init
		chs := make([]chan string, lenc)
		startTime := time.Now()
	//开始循环扫描每个cluster
		for i, cluster := range cluster_list {
			//如果cluster.name为空或者在白名单中，continue
			//控制并发度
			time.Sleep(time.Duration(3) * time.Second)
			//打印当前cluster，声明当前线程的通道,开启go routine
			chs[i] = make(chan string)
			go RunGet****Multi(i, fullName, timeout, chs[i], k8sZone, env, MetricType, cluster.name)
		}
	//检查通道返回值，累计完成任务数
		for _, ch := range chs {
			if ch == nil {
				continue
			}
			fmt.Println(<-ch)
			taskComplete += 1
		}
		
		endTime :=  time.Now()
		fmt.Printf("MultiScan finished. Process time %s. Task complete %d/%d\n", endTime.Sub(startTime), taskComplete, lenc)
	}
}

//routine函数,保证线程返回结果通过通道传回,否则等待超时
func  RunGet****Multi(task_id int, cluster string, timeout int, ch chan string, k8s string, env string, scanType string, clusterO string) {
	ch_run :=  make(chan string)
	//套用线程进行巡检函数
	go runGet****Multi(task_id, cluster, ch_run, k8s, env, scanType, cluster0)
	select {
	//正常返回
	case re := <-ch_run:
		ch <- re
	/判断超时
	case <-time.After(time.Duration(timeout) * time.Second):
		re := fmt.Sprintf("task id %d, timeout", task_id)
		ch <- re
	}
}

//实际巡检函数部分
func runGet****Multi(task_id int, cluster string,  ch chan string, k8s string, env string, scanType string, cluster0 string) {
	//获取巡检扫描函数的结果struct list
	resultList := inspectionFunc(k8s, cluster, env, scanType)
	//失败时返回失败信息给线程通道
	if ... {
		ch <- fmt.Sprintf("task id %d, cluster %s failed!", task_id, cluster)
	}
	//对结果进行处理和判断
	...
	//最终写入风险metric元数据表和风险明细表
	...
	//刷新健康度表
	...
	//正常处理后打印返回值给线程的通道
	ch <- fmt.Sprintf("task id %d, cluster %s completed", task_id,  cluster)
}

```

### 小结

巡检系统本身是监控/扫描数据的整合和统计，比起时效性更好的告警系统，它主要是找出一些依靠监控难以发现或者不能在早期发现的

**隐患**问题，是监控系统的补充，如果有能力设计模型进行训练，或许能够进行报警预知，再配套上自愈能力，效果就非常可观了。

### 参考

[美团MySQL巡检系统](http://tech.meituan.com/2020/06/04/mysql-detection-system.html)

### 其他碎碎念

时值五一，已经在家隔离1个月多，除了隔三差五的核酸检测和日常的抢菜团购，我也不幸在转正后1个月出头被公司裁员。我想在疫情不断、

经济不景气的情况下大背景下，互联网公司多少有点寒冬的味道了。本以为公司表面上没有任何动静大家相安无事，没想到暗流涌动，直接一

波20%的大裁员，部门指标下来，才来7个月的我首当其冲了。很多时候回想起来，至少自己在当时完全付出了，努力了，虽然结果并不满意，

但只要自己不后悔，也是好的。人生路漫漫，仍当上下而求索。