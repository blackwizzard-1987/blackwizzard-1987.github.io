---
layout:     post
title:      MySQL MGR节点硬件升级操作思路和步骤(上)
subtitle:  	
date:       2020-02-15
author:     RC
header-img: 
catalog: true
tags:
    - MySQL
    - MGR
    - 高可用
---

## 背景

线上一条业务线的MySQL MGR节点需要进行硬件升级(磁盘更换为SSD)，该组复制共3个成员，使用single-primary的模式。

由于我们使用的是同城的线下机房，更换磁盘需要需要人工更换并且重装系统，大概需要1-2天时间完成，这期间需要保证业务不中断并且高可用可用。

升级过程中我们主要关注的点：

1.硬件升级过程中的HA

单节点 or 维持RG

2.是否可以直接加入新节点

IP限制？白名单？

3.主节点的切换方式

kill or stop

4.其他

步长问题，慢日志参数问题

## 操作思路

需要额外2台机器，其中一台D作为新的主节点已升级完毕，另一台可以用虚拟机等作为临时节点E

在时间点T1将额外的机器D和E加入原A,B,C的组复制中

成功后，组成员依次离组，D开启新的组复制，然后原主节点A和加入，此时B和C适当保留文件系统的需要文件后关机，等待硬件升级

B和C硬件升级完毕及Linux系统重装后，在时间点T2将B和C加入D的组复制

成功后，组成员依次离组，BCD检查数据库参数是否还原和更新，之后重启，开启新的组复制，所有节点升级完毕

>为保证数据一致，再进行切换主节点操作和加入新节点时，需要关闭VIP，业务将停滞数分钟，需要在业务低峰进行


## 流程概览

![1](https://i.postimg.cc/Kz4xCCMG/image.png)

## 测试环境测试

```html
SET GLOBAL group_replication_ip_whitelist="xx.xx.xx.0/24";
show variables like '%group_replication_ip_whitelist%';
SET GLOBAL group_replication_ip_whitelist=AUTOMATIC;
--需要停止GR后才能更改，0/24表示第四段数字为0-255

SET GLOBAL group_replication_group_seeds=
'xx.xx.xx.186:33060,xx.xx.xx.187:33060,xx.xx.xx.188:33060,xx.xx.xx.184:33060,xx.xx.xx.185:33060';
show variables like '%group_replication_group_seeds%';
--可以在线更改
--170和171以修改后的my.cnf直接启动

4个router上都有MySQL运行，但没有任何数据，不影响

以主节点的备份还原MySQL后，
启动，
以recovery chanel加入RG，主节点开启引导，没有错误
--明天测试171动态加入，4个节点的白名单改为automatic，理论上可以加入任意网段的节点

--动态修改seeds后，需要修改my.cnf的seeds为100,101,170
--之后五节点，切换170为主，下线100,101，更换SSD（更换之前原磁盘内容是否需要备份），然后重做，上线，以170为主加入RG，再下线157和171
--动态更改seeds为100,101,170？（不需要）
--此时3个节点170,100,101停止RG，重启MySQL使新的配置文件生效（包括seeds（3个），慢查询，io，步长设置）
--建立新的RG，以170为主节点

--网卡设置，ifcfg后面为使用的网卡口
--koala服务器使用的ip协议版本都是4
/etc/sysconfig/network-scripts/ifcfg-enp2s0f0
与101等机器配置有出入，是否有问题

--第二台171以主节点101的my.cnf修改后加入，seed为5个，未修改白名单，可以动态加入（recovery chanel+主节点引导）

--切换主节点为170的过程中，依次主动离组，下线节点状态不为unreachable，当GR只剩2个node时，主节点依然可以提供读写
--根据博客，如果是一口气宕机（kill等）3个节点，即使主节点的super_read_only=off,理论上是不提供读写的
--https://www.cnblogs.com/xinysu/p/6674832.html#_label3_1_0_4
--170成为新的单个P节点后，仍可读写，推论为正常离组不影响RG的读写功能

--其他节点在170之后加入时，set global group_replication_bootstrap_group = OFF; start group_replication; 原主节点101最后加入。

--将100和101离组，重做MySQL（模拟更换SSD），之后用170的备份还原，配置文件更改seeds为5等，以recovery加入RG
--同步后，下线171和157，其余成员依次停止GR，更改配置文件seeds为3，重启MySQL，重建RG

--100和101的配置文件用170的修改，或者用自己原来的修改（安装后再改）

--下线171和157，stop group_replication; service mysql stop;

--组内成员依次下线，100,101,170： stop group_replication; 均显示为OFFLINE SECONDARY

--关闭mysql进程，修改100,101,170的参数（包括seeds（3个），慢查询，io，步长设置），之后重启
--101的seed参数其实一直没变，但因为要改其他参数，所以也要重启

--修改完成重启后，170设置set global group_replication_bootstrap_group = ON;start group_replication;开启新组
--101和100设置set global group_replication_bootstrap_group = OFF;start group_replication;加入新组
```
