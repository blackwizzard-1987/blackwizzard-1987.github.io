---
layout:     post
title:      电子表单和附件材料字段梳理
subtitle:
date:       2024-10-20
author:     RC
header-img:
catalog: true
tags:
    - 表单电子化
    - NLP
    - 自动化脚本
    - 政务数据治理
    - 标签和分组
---

### 背景

随着天府蓉易享二期上线后各项功能和运营逐渐平稳，出于**易用、好用，简便化事项配置上架的操作流程，对平台现有数据的数据治理工作也提出了新的要求**。

基于平台现有的**大量电子表单和附件材料中包含的表单**，如果能够统一对表单中填写的字段进行提取，并进行词频统计和标准化、分类分组处理，进行**填报字段的”合并“**，就能够进行一定的配置电子表单字段推荐功能。用户在配置电子表单时，根据分类分组可以迅速找到所需类型的字段，并直接使用，最终快速形成标准化字段的电子表单，或者保存为模板进行复用，省去了人工手动输入的麻烦和配置多个填报材料的繁琐。

> 蓉易享本身业务中政府端人员需要上架事项供企业申报，上架过程中均会配置电子表单搜集申报主体的各种信息，基于历史流程，这部分数据分为两类，一类是附件材料下载模板中包含的表单，这部分材料在下载后需要进行填报再上传；一类是申报时需要在平台填写的电子表单，这部分直接保存后成为电子申报材料。

> 电子表单可以一定程度上获取申报主体信息，但无法完全替代附件材料的表单，因为它们的格式更加丰富，包含的信息也更多

### 梳理过程

整个过程分为**字段提取，字段筛选，字段分类分组，字段标准化**4个阶段。

字段提取部分，对于电子表单的字段，直接后台拉数据；对于附件材料的表单，共980+，包含pdf、word、excel格式，对最多的word格式进行了程序处理，关键在于识别合并单元格。通过程序自动化提取。

字段筛选部分和分类分组通过文心一言辅助，纯人工处理高频字段。

字段分类分组的依据为政策标签体系的分类分组，并在此基础上进行了扩展。

字段标准化主要是合并能合并的字段，保证叫法的统一，并统一命名词根。

#### 字段提取

字段提取出的数据是后续工作开展的基础数据，分为原电子表单已有字段和原附件材料表单字段两个部分组成。

**对于原电子表单已有字段**，我们根据后台数据库关联关系，可以直接按照事项->电子表单字段的关系获取数据然后落表，内容大致如下：

![1](https://i.postimg.cc/BnMQJbbb/1.png)

可以看到不同事项对应的电子表单配置的填报字段的内容、个数都是不同的，这部分数据总**共涉及2368个事项、16198个字段**，按照字段名称去重后，得到字段名称、字段出现频率的统计表，共1273条:

![2](https://i.postimg.cc/tCnhZ0W9/2.png)

由于默认表单的存在，出现最高频率的字段包含了三个固定字段，除此之外共有1200+不同的字段被原电子表单使用，说明**平台本身的业务内容宽度是非常大的**，涉及各行各业以及企业、企业人才的方方面面。

**对于附件材料中的模板材料表单中的字段**，我们先从后台数据库表中拿到所有附件材料为可下载模板材料的
清单，然后根据清单中材料的地址和名字，通过MinIO的mc find和mc get命令，批量从文件服务器下载对应的模板材料到Linux服务器的指定目录，然后进行打包，下载到本地。

解压后总共有**983个模板材料文件**，其中24个材料为pdf、excel格式，剩下的材料均为word格式。

由于模板材料文件太多，如果单纯人工去一个个打开然后复制粘贴，效率太低，因此考虑使用程序来处理word格式的模板材料，并提取其中的表单字段。剩余的其他格式，因为数量很少，就直接人工处理。

借助于**Python的docx库的Document模块**，我们可以直接遍历word中每个表单和它们的每个单元格：

```html
doc = Document(docx_path)
tables = doc.tables
for table in tables:
	# 获取表格的行数和列数
	num_rows = len(table.rows)
	num_cols = len(table.columns)
	
	# 获取所有单元格列表、表宽度、和单元格数目
	cells = table._cells
	cols = table._column_count
	length = len(cells)
	...
```

这里有个很关键的问题就是表单中会存在大量的**合并单元格**：

![3](https://i.postimg.cc/LXYHBMSV/3.png)


当然，这类单元格大多为其他单元格的一个子标题，或者说title，但部分银行、社保等用到的回执单等财务相关的表格中也会频繁出现，因此需要单独处理。

那么怎么判断单元格是不是合并单元格呢？（这部分逻辑借助了网上的思路改写）

合并单元格在word的表格中有几个特点：

- 按照从左到右，从上到下的默认顺序，第一个出现重复的单元格，就是合并单元格区域的左上角的单元格；最后一次出现重复的单元格，就是右下角的单元格；

- 合并单元格合并的单元格在单元格的数组中是被认为内容是相同的，不同的是每个合并单元格的顺序；

由此我们可以得到结论，将所有单元格作为一个数组，如果从**正序遍历找到的单元格和倒序找到的单元格内容相同但索引值不同时，它就是合并单元格**。

相关代码如下：

```html
# 获取表格中的所有单元格
        cells = table._cells
        cols = table._column_count
        length = len(cells)
        # print(cols, length)   
        
        j_index = 0
        # 建立坐标系，找出合并单元格覆盖的范围和范围内的表单字段
        # 合并单元格在第一列的，认为覆盖所在行的所有字段，包括表头（不考虑一行两个合并字段）
        # 合并单元格在第一行的，认为覆盖所在列的所有字段（不考虑一列两个合并字段）
        for i, cell in enumerate(cells):
            if cell in cells[:i]: # 如果该单元格不是在表中第一次出现则跳过
                continue
            for j in range(length - 1, 0, -1): # 倒序查找
                if cell is cells[j]: # 找到"相同"的单元格，如果没有"合并"单元格，则会倒序找到"自己"
                    j_index = j
                    break
            if i != j_index: # 如果正序查找和倒序查找的索引值不同，则说明是"合并"单元格
                r1, c1 = divmod(i, cols) # 合并单元格区域的"起始"位置，同时也是左上角单元格的行列坐标
                r2, c2 = divmod(j_index, cols) # 合并单元格区域的"结束"位置，同时也是右下角单元格的行列信息
                column_name = cell.text.replace("：", " ").replace('\u3000', '').strip()
                if not filter_columns(column_name) and has_header:
                    # print(f"合并单元格:{column_name}, 位置:{r1}{c1}到{r2}{c2}, 表头:{has_header}")
                    merge_cell_dict[column_name] = has_header
                else:
                    pass 
```

这段代码寻找正序第一次在数组中出现的单元格的倒序索引值，并和正序遍历的索引值比较，如果两者不同，就是合并单元格，如果两者相同，就是一般单元格。类似于：

(...非合并1, 非合并2, 合并1, 合并1, 合并1, 合并1, 非合并3, 非合并4...)

通过识别合并单元格后，程序再加上对表单一些无效文字、换行、省略等字符的过滤，就可以完成一个word文件的表单字段提取了（对应上图的表单）：

![4](https://i.postimg.cc/PxwMGPhv/4.png)

通过批量程序读取和录入数据库表，附件模板材料中的表单最终包含了**664个模板材料的23700个表单字段**。

将两部分的字段按照**来源标记后去重，融合在一个表中，得到6128个填报字段和它们的出现频率表**：

![5](https://i.postimg.cc/fLmY2pjx/5.png)

![6](https://i.postimg.cc/ZKG4ZQr9/6.png)

至此完成了所有表单字段的提取工作，通过该表的数据，作为后续处理的基础数据。


### 总结和展望

### 参考





