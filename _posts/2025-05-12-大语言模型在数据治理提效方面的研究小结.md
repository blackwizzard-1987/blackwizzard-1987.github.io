---
layout:     post
title:      大语言模型在数据治理提效方面的研究小结
subtitle:
date:       2025-05-12
author:     RC
header-img:
catalog: true
tags:
    - 大模型
    - DeepSeek API
    - 数据治理
	- 提效
---

### 背景

最近deepseek的API流量重新对公众开放，加上数据组也希望研究一下大语言模型在数据治理方面提效的场景，于是我花了1周的时间仔细研究了下，主要通过**提示词调用deepseek两个模型的API接口完成本地文件的解析工作**。

共探索完成3个简单应用场景+1个上下文拼接场景，包含数据质量稽查、数据标签管理，以及数据血缘分析。

### 具体场景

#### 数据质量稽查-身份证号有效性验证

- 使用模型：deepseek-v3
- 源数据来源：本地Excel文件
- 源数据大小：含1003条身份证号
- 数据质量规则：验证长度/前17位/最后一位/校验位是否正确
- 输出格式：新增一列，标记有效/无效，无效的判定会给出无效原因
- 模型分析步骤：一个
- 模型分析时间：138秒
- 输出结果误差率：约2%
- 结果示例：

![1](https://i.postimg.cc/y6RbN95W/WPS-1.jpg)

这个场景其实用程序可以完美解决，主要是初步看下整体思路的实现情况。

在过程中发现大模型每次的输出结果都有波动，并且无论怎么强调规则还是会**出现“AI幻觉”**般的操作，把明显错误的结果当成结果输出。

提示词如下：

![2](https://i.postimg.cc/P5V4yrcB/629-A4-E0-B-0-C07-48a5-A59-A-D2-F04-BD6-D40-F.png)

问题主要集中在第四条规则的校验，换成程序就是：

```html
    # 校验码计算
    weights = [7, 9, 10, 5, 8, 4, 2, 1, 6, 3, 7, 9, 10, 5, 8, 4, 2]  # 权重因子
    check_codes = '10X98765432'  # 校验码表

    # 计算校验码
    sum_ = sum(int(id_card[i]) * weights[i] for i in range(17))
    check_code = check_codes[sum_ % 11]

    # 校验码对比
    if id_card[17].upper() != check_code:
        print(f"{check_code}身份证号校验码错误。")
        return False
```

V3模型始终会算错一些，可能也是"随机性"的一部分。

#### 数据标签管理-数据分类打标

- 使用模型：deepseek-v3
- 源数据来源：本地表结构文件
- 源数据大小：含13张表，约300个字段
- 数据分类规则：每张表含业务主分类和子分类，2-3个业务标签
- 输出格式：主分类，子分类，标签列表，核心字段示例，标签标记
- 模型分析步骤：一个
- 模型分析时间：186秒
- 输出结果期望：可接受
- 结果示例：

![3](https://i.postimg.cc/Bb2DgDS2/24651-E4-B-6499-4ff6-B8-A5-FFCE8352-EF68.png)

这个场景在一开始效果不太理想，后面加入了**system的提示词（角色预定义）**，并且告知了业务场景描述：

```html
    def analyze_table(self, ddl):
        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "你是业务数据架构师，擅长从业务视角解析数据结构"},
                {"role": "user", "content": self.generate_prompt(ddl)}
            ],
            temperature=0.5,
            max_tokens=2000,
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
```

```html
        self.business_context = """业务场景描述：
执法人员通过移动端开展以下工作：
1. 市场主体日常巡查（根据检查事项进行核查）
2. 执法人员现场亮码执法
3. 执法完成后被检查企业扫码评价
"""

    def generate_prompt(self, ddl):
        return f"""基于以下业务场景分析表结构：
{self.business_context}

请完成：
1. 推断表所属业务模块（2级分类，如：巡查管理→事项核查）
2. 生成2个业务特征标签（如：人员基本信息、市场主体基本信息、执法记录信息等）
3. 标注3-5个关键字段的业务作用

输出要求：
- 分类格式：主类→子类
- 标签体现数据特性
- 字段说明使用业务语言
- JSON格式示例：
{{
  "table_name": "表名",
  "classification": ["主类", "主类→子类"],
  "tags": ["标签1", "标签2"],
  "key_fields": {{
    "字段名": "业务作用描述"
  }}
}} 

待分析表结构：
{ddl}"""
```

加入背景和角色提示后，基本能够通过表结构完成数据的分类和打标，形成快速检索的依据。

#### 数据血缘分析-元数据采集和血缘分析图

- 使用模型：deepseek-v3
- 源数据来源：本地表结构文件
- 源数据大小：含13张表，约300个字段
- 血缘分析规则：提取元数据，根据元数据生成表之间的关联关系（含关联字段）
- 输出格式：元数据提取文件、血缘分析mermaid ER图
- 模型分析步骤：两个
- 模型分析时间：560秒
- 输出结果期望：可接受
- 结果示例：

![4](https://i.postimg.cc/bY0smq00/4-B81-AEEF-4033-4e76-A763-B967-A9-AAA1-F7.png)

![5](https://i.postimg.cc/tC27HDMY/9-FB9-F143-2340-4e07-B44-F-B9-CD0-ED40-B65.png)

这个场景在刚开始尝试时遇到两个问题，首先是**直接让大模型读DDL文件然后输出血缘关系不能完成**，主要是因为字段太多，干扰了一部分理解。另外由于输入**token限制**导致只有部分表的内容得到了解析。

为了解决这些问题，将整体流程拆分为了两个步骤，第一个步骤读取DDL文件内容，解析为标准的表结构，然后让大模型**提取每个表的元数据信息（仅含核心字段、主键、外键）**；第二个步骤通过步骤一的结果作为输入，然后按照要求完成mermaid ER图的代码：

```html
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
        self.prompt_template = """请分析以下SQL DDL语句，提取以下元数据信息：
1. 表名
2. 字段名（只需关注主键、外键、有明确数据流向或数据关系的字段）
3. 字段作用（简明的业务含义）
4. 血缘分析相关性（数据来源、流向或关系）

输出要求：
- 仅返回JSON格式，不要额外解释
- 忽略与数据关系无关的普通字段
- 结构示例：
{{
  "table_name": "表名",
  "metadata": [
    {{
      "field_name": "字段名",
      "purpose": "字段作用",
      "lineage": "血缘分析相关性"
    }}
  ]
}}"""
```

```html
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
        self.analysis_prompt = """请基于以下元数据生成Mermaid ER关系图：
1. 识别主外键关系，使用ER图标准语法
2. 表结构展示要求：
   - 主键标注PK
   - 外键标注FK
   - 字段类型统一使用string
   - 字段注释保留原意
3. 关系线使用||--o{ 表示一对多
4. 关系说明使用双引号标注在关系线旁
5.血缘关系总结一段话（100字）

示例格式（以bus_examine_activity和bus_scan_record为例）：
erDiagram
    bus_examine_activity ||--o{ bus_scan_record : "扫码记录"
    bus_scan_record {
        string id PK "主键"
        string task_id FK "任务ID"
    }

请严格遵循以下JSON格式返回：
{
  "summary": "血缘关系总结一段话",
  "er_diagram": "完整的erDiagram代码"
}"""
```

ER图代码这块的效果，是根据V3模型多次回答出的不同结果的效果整合出的，这里可以看出虽然大模型不能像程序那样精准，但**同时也具有了“创造性”**。同样，最终结果非常依赖于元数据的质量，而元数据的质量又和表结构定义绑定，因此可以认为如果想要更好的效果，**前置的标注工作——无论是模型自动完成还是人工校准，是必不可少的大量工作**。

### 上下文拼接

很明显，当本地DDL文件过大时，我们没法一次性将所有元数据信息给大模型分析，如果简单的拆分为多份，又会导致每一个部分单独成立，整体无法完整显示血缘关系。

> 因为调用API接口使用大模型每次都是新开一轮对话，和网页版不一样，大模型是不知道之前的历史对话内容的

deepseek官网给出的上下文拼接方法是将上一轮对话的输出结果作为assistant的content和下一轮对话的提示词一起喂给模型。

由于元数据的提取不受此影响，所以我们可以先将所有表的元数据解析出来，然后分批次读取元数据信息，**每次让大模型根据批次的新增元数据信息更新血缘关系，并保留历史血缘关系**即可。

这个流程使用下来本身没有问题，但因为模型处理过多信息，会“编造”出一些元数据没有的“看起来像”的字段，所以我又加入了白名单机制进行校验，不允许模型使用自创的非法字段：

```html
        # 强化系统消息
        system_msg = """你是一个严格遵守规则的数据血缘分析专家：
        1. 必须严格使用字段白名单
        2. 每个字段必须有明确的血缘依据
        3. 严格遵守mermaid ER图代码规范"""
```

```html
        base_prompt = """这是一个多轮对话，请根据以下信息更新Mermaid ER图的代码：
1. 当前ER图状态：
{}
2. 新增元数据（必须严格遵循）：
{}
3. 生成规则（违规将导致错误）：
- 严禁添加未明确列出的字段（允许字段：{}）
- 保留所有历史ER图数据
- 每个表最多显示5个核心字段
- 外键关系必须匹配字段白名单
- 关系说明使用双引号标注在关系线旁，如："examine_activity_id 关联检查活动"
- 严格按照ER图代码规范编写
- 表结构展示要求：
   - 主键标注PK
   - 外键标注FK
   - 字段类型统一使用string
   - 其他字段标注注释，保留业务原意
   - 示例：
        string id PK "唯一标识"
        string dept_id_alias FK "关联检查主体id"
        string check_matter_code "检查事项编码"

输出格式要求：
```mermaid
erDiagram
合规的ER图代码
```"""
```

经过这轮调整，大模型的输出基本稳定，be like：

```html
    sys_user {
        string user_id PK "唯一标识用户"
        string dept_id FK "关联部门"
        string user_name "唯一登录标识"
        string enforcement_number "执法证件信息"
        string id_card "身份验证"
    }

    sys_role {
        string role_id PK "唯一标识角色"
        string role_name "角色名称"
        string role_key "权限定义"
        string data_scope "数据访问范围"
        string status "可用状态"
    }
    sys_user_role }o--|| sys_user : "user_id 关联用户"
    sys_user_role }o--|| sys_role : "role_id 关联角色"
```

最后，由于涉及表和关系太多，为了使整个图形更加易读，再对输出的mermaid ER图代码进行了顺序的调整。

最终效果：

![6](https://i.postimg.cc/xTvj05pK/B55-FC8-E7-C3-C5-47b8-AB8-D-446-A16202-FF8.png)

> 这里我发现大模型对于某些明显的关联关系依然没法100%覆盖，这是因为元数据的提取也是大模型完成的，会受到原表结构注释的影响，并且没有业务信息和程序信息引导，如果加入人工标注，效果能更好。

### 总结

通过以上4个简单应用场景，我们可以看出目前大模型提效数据治理这块的主要问题：

- 每个应用场景需要自定义定制化的提示词，提示词内容和随机性等模型参数会大幅影响模型效果（**提示词工程**）

- 由于随机性，**大模型每次回答相同问题不一定一致**，这是和程序最大的区别（但同时也有**创造性思维**）

- **上下文拼接**保持全局“清醒认知”的问题需要解决，将直接影响是否可投入大规模生产项目  

- 测试用的业务场景可能比较简单，需要多个项目场景共同验证

- 模型多轮对话（上下文）最多支持64K，即总输出+总输入之和，需要**尽量精简输入和输出，或者合理拆分为多个步骤**

- 大模型处理复杂问题（如血缘分析、AI问数等）**不可能通过单个步骤/组件完成**，需要系统性的标注成果（如详尽的元数据存储，表字段注释（包含指标、使用场景、关联关系）、版本控制-元数据变化跟踪、知识库等），**前置工作量非常大**

总之，大语言模型在特定场景下能够辅助完成精度要求不高的工作，生产环境使用需要大量前置标注工作，标注质量直接影响准确率。

> 这里还没研究到MCP协议的使用，标准化的工具应该能减少部分困境

### 参考

[DeepSeek官网](https://api-docs.deepseek.com/zh-cn/guides/reasoning_model)

[DeepSeek在数据领域的70个应用场景](https://mp.weixin.qq.com/s?__biz=MzA3MzEyMDQxMg==&mid=2450519958&idx=1&sn=161dbdde6d319b9b1253d286b2145245&poc_token=HBDZK2ijD-L3kJjpBHxKn2tGZDdqMRNNmMGRjufk)

