---
layout:     post
title:      基于Dify的问数应用设计开发小结
subtitle:
date:       2025-08-11
author:     RC
header-img:
catalog: true
tags:
    - 大模型
    - Dify
    - 自然语言处理
---


### 背景

目前，各行各业随着大模型普及，都纷纷建立了各种智能问答、智能客服、知识检索等应用，通过知识库检索、Agent化等方法，实现了**与AI自然语言对话完成特定场景任务**的目标。

在数据分析方面，如果我们能够通过和大模型对话的形式，完成数据查询和统计分析，将极大的**降低使用门槛**，使非专业的技术人员、业务人员都能够**自主查询和分析数据**。

出于这个理念，经过近两个月的努力，我们也是通过Dify成功迭代出一个自然语言问数的应用，虽然还谈不上商业化价值，但过程中确实学到了很多东西。本文对此进行简单介绍。

### 难点在哪

难点就三个，**准不准？快不快？连续不连续？**

首先我们要明白自然语言问数的原理，其实就是NL2SQL，即**自然语言转换为SQL查询语句**，这一点是肯定的，因为海量的数据不可能全部"喂"给大模型，而传统的智能问答系统使用**知识库召回片段完成定向检索的模式**，在问数这个场景下，**效果也不好**（后面会提到），所以只能通过写SQL完成查询，进而分析，主要流程为（简化版本）：

![1](https://i.postimg.cc/y6Fg4kZd/image.png)

可能这个时候有人就会说了，这个简单，就是**直接把数据库的表结构喂给大模型，然后直接提问**就行了。

确实，对于一个业务场景比较简单的系统，其表结构单一，没有歧义，不会引起AI幻觉，那确实可以直接省略其他优化，很直白的用表结构投喂，准确率就达到了。但问题在于，复杂场景下，一个应用要负责查询多个领域/业务条线的数据，那么就**需要问题分类，就需要提示词工程、schema增强去压缩有用的信息，需要约束AI的生成结果，避免幻觉**等等，而为了解决“快”的问题，你又要考虑**简单问题的模式化处理，历史问题的复用**，为了解决“连续回答”的问题，你又要**引入记忆池，对用户意图进行检测**...总之，在问数的场景下，怎么**提升准确度和速度**都是没错的，这也是整个应用优化的方向。

> 很直观的一点就是，从最初的demo（能用）到最终版本（好用），Dify的编排节点从一开始的几个增加了几十个，更别提各个代码执行节点背后的程序支撑，复杂程度呈几何级升

> 很棒的一点是，在我们的场景下，Dify的产品设计已经能够满足（除了官方说后面修复的发布后预览网页模式下，部分全局变量不生效的bug），当然，字节的扣子听说也很不错，但还没时间尝试。

### 探索过程

整个应用的探索过程称得上是摸着石头过河，毕竟没有相关设计经验，大模型相关的很多概念也是一知半解，只能依靠网上资料和官网的文档（deepseek API文档和Dify产品文档）慢慢摸索。

应用中很多的节点的程序编写以及架构和组件，都是和大模型多轮对话慢慢添加的，外部的需求、测试和反馈主要来自产品经理，总体符合测试，反馈，优化的流程，主要分为3个阶段：

![1](https://i.postimg.cc/JzX2PrQr/xiang-mu-gui-hua.png)

#### 起步阶段：准不准

这个阶段主要是满足问数应用最基本也是最核心的要求——**能够准确根据用户问题回答对应统计指标**。满足基本条件后，在实际场景下，我们还要考虑应用涵盖的**场景交叉**的问题、最终回答后的**用户引导**、**图形生成要求**等等。

##### 1、问题分类器

问题分类器主要保证了**应用涵盖的不同场景之间的隔离性**，因为每个场景的提示词和其他组件都是不相同的，按照dify的workflow设计，**问题分类这个组件**搭配合适的提示词，使用一般的LLM（如qwen-3.32b快速模式）即可比较准确的进行分类，保证用户问题->后续流程->场景之间的适配，同时，也可以直接在一开始就**拒绝回答通用性、常识性或者非统计性的不相干问题**，节约时间。

##### 2、提示词工程和schema增强描述

首先，我们需要在LLM处理生成SQL节点的system提示词中**明确模型的角色和任务**，并且给出**核心原则**（比如按照要求，参考表结构和理解用户问题，生成SQL），核心原则不宜过多，主要是帮助模型理解任务。

接下来，表结构对于整个应用来说重要性不言而喻，怎么让LLM更好的理解每个场景下面涉及的表是一个很基础但又很重要的问题。因为一般的关系型数据库的表结构，都是**大量离散信息的整合**，不适用于CoT(**Chain of Thoughts**)形式的框架，也不适合创造性内容，**对结果的准确性要求极高**，这也是自然语言问数的一个难点。

经过尝试，我们最终使用了**markdown格式**的改写版表结构作为LLM的提示词输入，主要包含了**表名、表描述、字段名、字段类型、字段空值与否、字段注释、字段示例值、主键和业务用途**。

需要注意的是，在梳理表结构后，需要结合实际业务，对某些**歧义性表结构内容进行约束**，对该**场景下面的通用内容进行约定**，在一般的场景中，涉及0-10张表的表结构，每张表约10-20字段基本没有大的问题。在关联表场景中，需要**追加关联表之间的关联关系描述**，包含关联的表和关联的字段信息。

这里也可以看出，**合理的表结构设计**，或者说**设计专门用于LLM使用的宽表**等，对于LLM的理解和降噪，提高准确性是很有帮助的。

同时，我们需要**对LLM的输出结果进行规范处理**，包含我们期望输出的内容（如json格式的SQL对），以及不希望模型输出的内容（如禁止输出其他内容，只需要SQL）。

另外，还需要在提示词末尾**给出1-2个用户问题和对应SQL的例子（即Few-Shot）**，也可以提高模型输出的准确率。

##### 3、决策引擎和图形生成

决策引擎是问题分类器进入分支后的又一个分支起点，主要用于**判断用户问题的两个维度：模糊性和复杂性**，并按照评估分数进入不同的后续分支处理。本质上是为了增加应用的泛用性和易用性。通过对用户问题的两个维度打分，可以更精细地处理不同类型问题，在准确度和效率上面都有所提高。

对于用户的**模糊查询**，比如：“广告投诉”、“噪音问题投诉”、“6月份群众投诉”等，这些**问题没有特别明确的业务维度或者时间周期**，所以，需要LLM根据我们约定的时间，作为统计周期，然后将相关字段作为业务维度，查询出所有的明细信息，然后**将这些信息整合起来形成统计摘要，最后反馈给用户**。这样做的好处是能够让不太懂业务或者分析的用户问题也能够找到他们想了解的方向，通过总览->引导问题->具体指标的路径，完成他们的数据分析探索。

对于用户的**简单查询**，比如“按类别统计本季度群众诉求前十”、“工单号23060003目前状态”、“上月群众诉求中投诉排名前五的部门”等，这些问题的业务维度非常明显且固定，也包含了明显的筛选条件或者计算口径及统计周期，对于这类**模式化的问题**，我们完全可以“枚举”可能的各种pattern，然后直接用**程序生成SQL**，极快又准，唯一的问题就是每个生成器都要定制化开发，并且不断地通过业务反哺完善。

剩下来的最后一类**复杂问题**，比如“成华区历史工单中环境卫生与市容秩序的数量比值？”、“预测下个季度的投诉趋势”、“市民最关心的问题是什么，有几个？分别是什么内容，哪个部门负责的”、“用折线图表示7月以来的投诉趋势”等，这些问题要么涉及到了**较复杂的统计口径**，比如环比、等比、比值，或者是**预测**类型，或者是**多个问题组合**，或者是**有图形生成要求**等等，我们都将他们划为复杂问题，必须借助LLM生成SQL。这里LLM的SQL准确度很依赖与第二个步骤中提示词工程的效果，我们也会发现即使temperature设置为0，模型依然会偶尔写错SQL（这里需要用**SQL校验器校验语法错误**，避免一部分问题，**AI幻觉依然不可避免**，比如无中生有某个不存在的字段）。但总体上，**LLM对于复杂问题的处理还是超乎想象，基本能够满足用户需求**。

图形生成要求我们通过Few-Shot能够轻松解决，只要给出一段**标准的Echarts Python代码**，模型就会根据实际图形要求生成各种图形，包括常见的**柱状图、折线图、饼图，以及雷达图、漏斗图**等等，不需要通过dify的Echarts插件进行标准化处理，枚举+分支太麻烦（虽然一开始我们就是这样做的）。

通过对用户问题的细分，不同路径的分支来具体处理不同类型和复杂度的问题，虽然应用整体框架更加复杂，**减少了可移植性**，但**易用性和性能会提高很多**，还是推荐做的。

这里的决策引擎也涉及到了第二个研究阶段解决“快不快“问题的办法，后面会继续介绍处理简单问题的程序规则生成器。

##### 4、用户引导和结果生成约束

这个部分的输出内容因为直接面向终端用户，所以是**看起来最简单但实际上最麻烦的**，因为始终无法绕开AI幻觉，但又希望能够借助于语言模型的向量化匹配能力发挥它的“创造性”，所以最后只能进行平衡和取舍。

###### 答非所问

**答非所问或者胡诌应该是问数场景中最忌讳的输出结果**，因为不是agent整个调用工具和思考链完成的任务，最后分析节点的LLM只会拿到用户问题、第一个LLM/规则引擎等写的SQL，以及SQL查询结果/摘要来回答问题。

一个很典型的问题就是，SQL没有写对，比如用户问的是处理时间平均天数，而SQL写的是count(1)，如果不特别说明，**模型极大概率会把这个count(1)的结果作为天数返回**。由于用户不知道后台数据，所以任何这类幻觉就会产生误导，甚至是**在用户追问后出现前后矛盾的情况**。

更隐蔽的情况是单一数字的输出，本来是xx类型的工单有多少条，模型很容易输出为xx类型的数量为多少条，容易产生有多少个类型的误解。

这里其实就是需要对输出节点的模型提校验SQL与用户语义是否一致的要求，即：

1、**保证SQL是正确的，否则直接回答事实（SQL错误的结果解读），不强行绑定错误结果到问题上**。

2、**精确解读，保证和SQL内容表达的指标含义一致，不含糊不产生歧义**。

3、**在1的基础上，如实回答并告知问题，比如目前查询结果是A，未包含B（用户问题）的数据**。

这样，至少在输出结果方面，模型没有明显的幻觉和歧义产生，为前面可能产生的SQL错误预留了解释余地，也为后续用户追问提供了空间。

约束例子如下：

```
### 1. **严格匹配验证**：
   - 比较用户问题{{#sys.query#}}与查询SQL{{#xx.result#}}的语义一致性
   - 当出现以下情况时如实告知无法回答：
     * 指标类型不匹配（如用户问平均值，SQL返回计数）
     * 维度缺失（如用户问分类排名，结果无分类字段）
     * 数据范围不符（如用户问投诉数据，结果无投诉记录）
   - 错误示例纠正：  
     ❌ 用户问“平均处理天数是多少？” → SQL返回count(*) → 应答：“平均天数为15天”（幻觉）  
     ✅ 正确应答：“当前查询返回的是工单数量（15条），未包含处理天数信息”

- **计数结果明确表述**：
  - 当SQL使用`COUNT()`且结果只有单一数字时：
    ✅ 正确表述："共有{数字}条咨询类型的工单记录"  
    ✅ 正确表述："咨询类工单总计{数字}条"  
    ❌ 禁止表述："咨询类型的数量为{数字}"（易误解为类型数量）  
    ❌ 禁止表述："有{数字}个咨询类型"
  - 必须包含**记录类型标识**（工单/诉求/来电信）

- **排序类结果表述**
  - 当用户问题涉及到最多、最少、最高、最低等最xx问题时，查询结果如果有多个，就取并列（如有）最xx的结果。

### 2. **结果处理增强**：
   - 当结果为空时明确告知：“未查询到相关数据”
   - 当结果与问题维度不符时：“当前结果包含[字段A][字段B]，但您的问题涉及[维度C]”

### 3.**用户友好处理**
  - ✅输出结果只需要回答用户问题和生成引导模板内容，不需要其他回复内容。
  - ❌输出结果不要包含任何根据SQL查询结果、查询SQL的描述、"引导内容"、“回答”字样。
```

###### 节外生枝

目前的大语言模型对话框基本都会在回答用户问题后给出3个左右的延伸问题，用户引导用户继续提问。这个引导问题看似很平常，实际上操作起来容易问题——即误导用户，主要有以下表现：

1、引入与当前知识库/表结构无关的主题（如人口、面积等不存在的指标）。

2、引入和之前问题和核心结果完全无关的新主题，比如用户问A分类，查询结果包含了A、B、C分类，但模型通过知识库/表结构推断出了D分类作为延申问题。

3、因果性问题，容易脱离数据分析本身，而回到业务场景中。

**规避以上表现只是让模型的新问题不出大问题，而如果紧贴原问题，或者对问题进行延伸**，这个目前我们也只是初步达到效果，即**核心事实约束后的排列组合**，我们需要告诉模型怎么提取用户查询结果的核心事实，以及怎么”拼接“好引导问题，框定范围后，模型有限的发挥(t=0.1)**基本不会产生脱离主题的问题，或者接下来难以回答的问题**，提示词举例如下：

```
## 引导内容模板

基于我们刚刚讨论的**`{用户问题关键词提炼}`**相关内容，您可能还想了解：

- 根据用户问题生成的问题举例1
- 根据用户问题生成的问题举例2
- 根据用户问题生成的问题举例3

或者直接提出您关心的问题，我会为您详细解答！

### 2、用户引导内容生成规则（严格遵循）

**引导问题必须同时满足以下条件**：

1. **输入源限制**：

- 仅允许使用：
  ✅ 用户原始问题：`{{#sys.query#}}`
  ✅ SQL查询结果中的**核心事实**（最多/最少/趋势等直接答案）
- 禁止使用：
  ❌ SQL中LIMIT返回的其他次要结果项
  ❌ 表中存在但未在用户问题或核心结果中出现的字段
  ❌ 表中不存在的字段

2.**关键事实提取方法**:

- 从SQL结果解析核心事实：
  排序类查询（ORDER BY+LIMIT）→ 取第一条结果
  统计类查询（COUNT/SUM）→ 取数值最大的项
  趋势类查询 → 取变化最显著的项

3. **四要素结构**：
   [时间范围] + [原子指标] + [维度描述] + [关键词]
   
   原子指标：仅限表字段（ldlx/blzt/ssqy/cgwthyxl等）
   关键词：群众诉求/来电信/工单三选一
   维度描述：仅限ssqy(区域)/blzt(状态)/clqx(时效)等基础维度
   时间范围处理：
   time_range = (
   提取用户问题中的时间 or
   提取SQL中的WHERE时间条件 or
   "最近一月"  # 默认)

4.**严格禁止行为**：

- 🚫 禁止引入用户问题和核心结果均未提及的新主题（如SQL返回[井盖,公厕,违建]，但核心结果是"井盖最多"，则禁用公厕/违建）
- 🚫 禁止使用表中存在但上下文未出现的字段
- 🚫 禁止生成与当前查询无关的问题
- 🚫 禁止引入表结构未涉及的新主题（如人口、面积等不存在字段）
- 🚫 禁止生成需要关联表但未激活的问题（如未查询转办表时，禁止生成"转办原因"类问题）
- 🚫 禁止生成结果中不存在的维度组合问题（如结果无bldw字段时，禁止生成"办理单位"类问题）
- 🚫 禁止生成超出当前查询范围的推测性问题（如"为何没有记录" → 改为"是否有记录"）
- 🚫 禁止使用任何因果性词汇（"为什么"、"原因"、"为何"）
```

这实际上也是一种生成约束，虽然不会显得那么”智能“，但至少不会犯错。毕竟一千个读者有一千个哈姆雷特，用户真正的诉求很难揣摩。

#### 优化阶段：快不快

快不快绝对是AI对话聊天时用户最直接的感受，很多模型分为了深度思考和快速模式，并且**深度思考模式中通过流式返回输出**（即模型的返回内容连续出现直至输出所有内容，而不是转圈转很久然后输出所有内容，快慢和模型返回token速率有关），淡化这种时间上的“长”的感受。

对本文中的AI大模型问数应用而言，由于不是agent操作，简单分出了“写SQL的LLM节点”和“最终分析并输出结果的LLM节点”这两个**核心部分，是必须要使用大模型的深度思考（长思考）模式的**，否则准确性会大打折扣（特别是对于追问的问题和复杂问题的处理），因此，如何提高这两个节点的速度成为了提升快不快整体感受的关键。

##### 规则生成器

引入规则生成器就是为了配合上面提到的决策引擎，**将用户的简单问题直接程序化处理**，不需要大模型介入。其原理也很简单，就是**模块化拆解和处理用户问题，然后通过一定范围的枚举完成解析和映射**。

通过设置固定的pattern，然后正则等方式解析出用户问题中的维度关键词，映射为表中的字段名称，替换掉固定pattern中的变量，就拼成了完整的SQL。

这部分的程序配置规则需要包含表中的字典名和码值，以及一些常用的业务术语，比如如何提取行政区划：

```
# 简化区域映射配置
    "area_mapping": {
        "全市": "",
        "中心城区": ["锦江区", "青羊区", "金牛区", "武侯区", "成华区"],
        "成华区": "成华区",
        "锦江区": "锦江区",
        "青羊区": "青羊区",
        "金牛区": "金牛区",
        "武侯区": "武侯区",
        "高新区": "高新区",
        "天府新区": "天府新区",
        "龙泉驿区": "龙泉驿区",
        "青白江区": "青白江区",
        "新都区": "新都区",
        "温江区": "温江区",
        "双流区": "双流区",
        "郫都区": "郫都区",
        "新津区": "新津区",
        "都江堰市": "都江堰市",
        "彭州市": "彭州市",
        "邛崃市": "邛崃市",
        "崇州市": "崇州市",
        "简阳市": "简阳市",
        "金堂县": "金堂县",
        "大邑县": "大邑县",
        "蒲江县": "蒲江县"
    },

def _extract_area_filter_simple(query: str) -> str:
    """提取区域过滤条件"""
    area_map = RULE_ENGINE_CONFIG["area_mapping"]
    
    # 1. 优先匹配配置中的区域名称（精确匹配）
    for area_name, area_value in area_map.items():
        # 使用正则表达式确保是独立词或带标点的词
        pattern = r'(^|\s|,|，|。|、)' + re.escape(area_name) + r'($|\s|,|，|。|、)'
        if re.search(pattern, query):
            if area_name == "全市":
                return ""
            if isinstance(area_value, list):
                areas = [f"'{a.strip()}'" for a in area_value]
                return f"ssqy IN ({', '.join(areas)})"
            elif area_value:
                return f"ssqy = '{area_value}'"
    
    # 2. 尝试匹配"XX区/县/市"格式的区域名称
    if match := re.search(r"([\u4e00-\u9fa5]{2,4}(?:区|县|市))", query):
        area_name = match.group(1)
        if area_name in area_map:
            area_value = area_map[area_name]
            if isinstance(area_value, list):
                areas = [f"'{a.strip()}'" for a in area_value]
                return f"ssqy IN ({', '.join(areas)})"
            elif area_value:
                return f"ssqy = '{area_value}'"
    
    # 3. 最后尝试匹配区域名称（但要求至少包含区/县/市字样，避免部分匹配）
    area_names_with_suffix = [name for name in area_map.keys() if any(suffix in name for suffix in ["区", "县", "市"])]
    for area_name in area_names_with_suffix:
        if area_name in query and area_name != "全市":
            area_value = area_map[area_name]
            if isinstance(area_value, list):
                areas = [f"'{a.strip()}'" for a in area_value]
                return f"ssqy IN ({', '.join(areas)})"
            elif area_value:
                return f"ssqy = '{area_value}'"
    
    return ""
```

该节点的程序测试用例效果如下：

![2](https://i.postimg.cc/9M3h368K/jue-ce-yin-qing-he-gui-ze-sheng-cheng-qi-ju-li-qu-hua.png)

当然，规则生成器不是万能的，因为枚举范围一定是有限的（时间、地点等），在一定程度上，**用户的问题越模式化（即业务人员、分析师的“机械式”提问），规则生成器就越有用**，而用户问题越模糊、越复杂，规则生成器就没有什么作用了。

但在提速这个怎么干都不嫌多的问题上面，多一个路径选择，过滤掉部分简单问题，让LLM节点不介入，提高整体输出速度，也是一个很好的事情。

##### 历史问题匹配库

历史问题匹配库主要通过收集后台数据并利用起来，将**用户的常用问题标准化后给出标准的SQL查询**，当后续其他用户提出相似问题时，计算标准历史问题和用户问题的**相似度，满足一定条件就视为是历史问题**，直接取标准化后的SQL，绕过LLM节点写SQL，也算是曲线完成了提速的目的。

这里需要注意选取的用户问题应该是高频的，并且有一定代表性的常见问题，这部分用户问题的梳理和标准SQL的确定需要进行**一定量的数据梳理工作**。

相似度的计算可以依靠**字符串的相似度计算，取最高值即可**。

##### 算力资源的成本

可以看到，上面的两个方案都是通过其他方式解决部分快不快的问题，我们必须认识到，快不快实际上是**离线环境AI大模型应用**的某种**成本上的妥协**。对于离线环境，算力成本是不得不考虑的重要问题，无论是并发请求还是大模型的量化度，每个指标都决定了算力成本不可能很少（Qwen3-32b在两块A100的支持下勉强能用，因为它还有快速思考模式），这肯定也是实施项目需要考虑的。

而本地测试用的互联网大模型API，可选择的就很多，个人感觉火山引擎的deepseek-v3速度比深度探索自家的快了大约30%。

如果离线环境切换到线上使用大模型API，还需要考虑数据泄露的风险，这点主要还是从两个方面入手：

1、 **控制数据范围**​：对大模型使用的数据库业务表、指标表内容进行控制，保证数据库查询结果集合规；对政策文件、内部文件使用进行审核，仅保留非涉密有效信息。

2、 ​**大模型接口提供方核实**​：核实大模型接口提供方对于用户数据的用户条款内容，确保对方不会使用、泄露用户输入的数据（比如阿里云）。

#### 深入阶段：连续不连续

根据官方要求的格式提了一个issue之后，没多久就收到了热情的回复：

![3](https://i.postimg.cc/ryr1dvCj/dify-ji-qi-ren-hui-fu.png)

大概意思就是我们知道这是一个1.5.1版本的bug，但什么时候修复还没确定。关键是这个明显是它们的后台bot审核后直接写的，不得不说作为一家AI应用开发平台的公司，这点人工智能审核还是做的挺不错的：）。

### 实际效果概览

### 总结

### 参考


