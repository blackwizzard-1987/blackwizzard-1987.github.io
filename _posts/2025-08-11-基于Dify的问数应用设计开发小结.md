---
layout:     post
title:      基于Dify的问数应用设计开发小结
subtitle:
date:       2025-08-11
author:     RC
header-img:
catalog: true
tags:
    - 大模型
    - Dify
    - 自然语言处理
---


### 背景

目前，各行各业随着大模型普及，都纷纷建立了各种智能问答、智能客服、知识检索等应用，通过知识库检索、Agent化等方法，实现了**与AI自然语言对话完成特定场景任务**的目标。

在数据分析方面，如果我们能够通过和大模型对话的形式，完成数据查询和统计分析，将极大的**降低使用门槛**，使非专业的技术人员、业务人员都能够**自主查询和分析数据**。

出于这个理念，经过近两个月的努力，我们也是通过Dify成功迭代出一个自然语言问数的应用，虽然还谈不上商业化价值，但过程中确实学到了很多东西。本文对此进行简单介绍。

### 难点在哪

难点就三个，**准不准？快不快？连续不连续？**

首先我们要明白自然语言问数的原理，其实就是NL2SQL，即**自然语言转换为SQL查询语句**，这一点是肯定的，因为海量的数据不可能全部"喂"给大模型，而传统的智能问答系统使用**知识库召回片段完成定向检索的模式**，在问数这个场景下，**效果也不好**（后面会提到），所以只能通过写SQL完成查询，进而分析，主要流程为（简化版本）：

![1](https://i.postimg.cc/y6Fg4kZd/image.png)

可能这个时候有人就会说了，这个简单，就是**直接把数据库的表结构喂给大模型，然后直接提问**就行了。

确实，对于一个业务场景比较简单的系统，其表结构单一，没有歧义，不会引起AI幻觉，那确实可以直接省略其他优化，很直白的用表结构投喂，准确率就达到了。但问题在于，复杂场景下，一个应用要负责查询多个领域/业务条线的数据，那么就**需要问题分类，就需要提示词工程、schema增强去压缩有用的信息，需要约束AI的生成结果，避免幻觉**等等，而为了解决“快”的问题，你又要考虑**简单问题的模式化处理，历史问题的复用**，为了解决“连续回答”的问题，你又要**引入记忆池，对用户意图进行检测**...总之，在问数的场景下，怎么**提升准确度和速度**都是没错的，这也是整个应用优化的方向。

> 很直观的一点就是，从最初的demo（能用）到最终版本（好用），Dify的编排节点从一开始的几个增加了几十个，更别提各个代码执行节点背后的程序支撑，复杂程度呈几何级升

> 很棒的一点是，在我们的场景下，Dify的产品设计已经能够满足（除了官方说后面修复的发布后预览网页模式下，部分全局变量不生效的bug），当然，字节的扣子听说也很不错，但还没时间尝试。

### 探索过程

整个应用的探索过程称得上是摸着石头过河，毕竟没有相关设计经验，大模型相关的很多概念也是一知半解，只能依靠网上资料和官网的文档（deepseek API文档和Dify产品文档）慢慢摸索。

应用中很多的节点的程序编写以及架构和组件，都是和大模型多轮对话慢慢添加的，外部的需求、测试和反馈主要来自产品经理，总体符合测试，反馈，优化的流程，主要分为3个阶段：

![1](https://i.postimg.cc/JzX2PrQr/xiang-mu-gui-hua.png)

#### 起步阶段：准不准

这个阶段主要是满足问数应用最基本也是最核心的要求——**能够准确根据用户问题回答对应统计指标**。满足基本条件后，在实际场景下，我们还要考虑应用涵盖的**场景交叉**的问题、最终回答后的**用户引导**、**图形生成要求**等等。

1、**问题分类器**

问题分类器主要保证了**应用涵盖的不同场景之间的隔离性**，因为每个场景的提示词和其他组件都是不相同的，按照dify的workflow设计，**问题分类这个组件**搭配合适的提示词，使用一般的LLM（如qwen-3.32b快速模式）即可比较准确的进行分类，保证用户问题->后续流程->场景之间的适配，同时，也可以直接在一开始就**拒绝回答通用性、常识性或者非统计性的不相干问题**，节约时间。

2、**schema增强描述**

首先，我们需要在LLM处理生成SQL节点的system提示词中**明确模型的角色和任务**，并且给出**核心原则**（比如按照要求，参考表结构和理解用户问题，生成SQL），核心原则不宜过多，主要是帮助模型理解任务。

接下来，表结构对于整个应用来说重要性不言而喻，怎么让LLM更好的理解每个场景下面涉及的表是一个很基础但又很重要的问题。因为一般的关系型数据库的表结构，都是**大量离散信息的整合**，不适用于CoT(**Chain of Thoughts**)形式的框架，也不适合创造性内容，**对结果的准确性要求极高**，这也是自然语言问数的一个难点。

经过尝试，我们最终使用了**markdown格式**的改写版表结构作为LLM的提示词输入，主要包含了**表名、表描述、字段名、字段类型、字段空值与否、字段注释、字段示例值、主键和业务用途**。

需要注意的是，在梳理表结构后，需要结合实际业务，对某些**歧义性表结构内容进行约束**，对该**场景下面的通用内容进行约定**，在一般的场景中，涉及0-10张表的表结构，每张表约10-20字段基本没有大的问题。在关联表场景中，需要**追加关联表之间的关联关系描述**，包含关联的表和关联的字段信息。

这里也可以看出，**合理的表结构设计**，或者说**设计专门用于LLM使用的宽表**等，对于LLM的理解和降噪，提高准确性是很有帮助的。

同时，我们需要**对LLM的输出结果进行规范处理**，包含我们期望输出的内容（如json格式的SQL对），以及不希望模型输出的内容（如禁止输出其他内容，只需要SQL）。

另外，还需要在提示词末尾**给出1-2个用户问题和对应SQL的例子（即Few-Shot）**，也可以提高模型输出的准确率。

#### 优化阶段：快不快

#### 深入阶段：连续不连续

### 总结

### 参考




